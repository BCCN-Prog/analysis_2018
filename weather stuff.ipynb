{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\T480\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://github.com/m-colombo/Tensorflow-EchoStateNetwork/blob/master/esn_cell.py\n",
    "\n",
    "from tensorflow.python.ops import rnn_cell_impl\n",
    "from tensorflow.python.ops import init_ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.ops import random_ops\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import variable_scope as vs\n",
    "from tensorflow.python.framework.ops import convert_to_tensor\n",
    "\n",
    "\n",
    "class ESNCell(rnn_cell_impl.RNNCell):\n",
    "    \"\"\"Echo State Network Cell.\n",
    "\n",
    "    Based on http://www.faculty.jacobs-university.de/hjaeger/pubs/EchoStatesTechRep.pdf\n",
    "    Only the reservoir, the randomized recurrent layer, is modelled. The readout trainable layer\n",
    "    which map reservoir output to the target output is not implemented by this cell,\n",
    "    thus neither are feedback from readout to the reservoir (a quite common technique).\n",
    "\n",
    "    Here a practical guide to use Echo State Networks:\n",
    "    http://minds.jacobs-university.de/sites/default/files/uploads/papers/PracticalESN.pdf\n",
    "\n",
    "    Since at the moment TF doesn't provide a way to compute spectral radius\n",
    "    of a matrix the echo state property necessary condition `max(eig(W)) < 1` is approximated\n",
    "    scaling the norm 2 of the reservoir matrix which is an upper bound of the spectral radius.\n",
    "    See https://en.wikipedia.org/wiki/Matrix_norm, the section on induced norms.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_units, wr2_scale=0.7, connectivity=0.1, leaky=1.0, activation=math_ops.tanh,\n",
    "               win_init=init_ops.random_normal_initializer(),\n",
    "               wr_init=init_ops.random_normal_initializer(),\n",
    "               bias_init=init_ops.random_normal_initializer()):\n",
    "        \"\"\"Initialize the Echo State Network Cell.\n",
    "\n",
    "        Args:\n",
    "          num_units: Int or 0-D Int Tensor, the number of units in the reservoir\n",
    "          wr2_scale: desired norm2 of reservoir weight matrix.\n",
    "            `wr2_scale < 1` is a sufficient condition for echo state property.\n",
    "          connectivity: connection probability between two reservoir units\n",
    "          leaky: leaky parameter\n",
    "          activation: activation function\n",
    "          win_init: initializer for input weights\n",
    "          wr_init: used to initialize reservoir weights before applying connectivity mask and scaling\n",
    "          bias_init: initializer for biases\n",
    "        \"\"\"\n",
    "        self._num_units = num_units\n",
    "        self._leaky = leaky\n",
    "        self._activation = activation\n",
    "        \n",
    "        def _wr_initializer(shape, dtype, partition_info=None):\n",
    "            wr = wr_init(shape, dtype=dtype)\n",
    "\n",
    "            connectivity_mask = math_ops.cast(\n",
    "                  math_ops.less_equal(\n",
    "                    random_ops.random_uniform(shape),\n",
    "                    connectivity),\n",
    "                dtype)\n",
    "\n",
    "            wr = math_ops.multiply(wr, connectivity_mask)\n",
    "\n",
    "            wr_norm2 = math_ops.sqrt(math_ops.reduce_sum(math_ops.square(wr)))\n",
    "\n",
    "            is_norm_0 = math_ops.cast(math_ops.equal(wr_norm2, 0), dtype)\n",
    "\n",
    "            wr = wr * wr2_scale / (wr_norm2 + 1 * is_norm_0)\n",
    "\n",
    "            return wr\n",
    "    \n",
    "        self._win_initializer = win_init\n",
    "        self._bias_initializer = bias_init\n",
    "        self._wr_initializer = _wr_initializer\n",
    "        \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return self._num_units\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return self._num_units\n",
    "\n",
    "    def __call__(self, inputs, state, scope=None):\n",
    "        \n",
    "        \"\"\" Run one step of ESN Cell\n",
    "\n",
    "            Args:\n",
    "              inputs: `2-D Tensor` with shape `[batch_size x input_size]`.\n",
    "              state: `2-D Tensor` with shape `[batch_size x self.state_size]`.\n",
    "              scope: VariableScope for the created subgraph; defaults to class `ESNCell`.\n",
    "\n",
    "            Returns:\n",
    "              A tuple `(output, new_state)`, computed as\n",
    "              `output = new_state = (1 - leaky) * state + leaky * activation(Win * input + Wr * state + B)`.\n",
    "\n",
    "            Raises:\n",
    "              ValueError: if `inputs` or `state` tensor size mismatch the previously provided dimension.\n",
    "        \"\"\"\n",
    "\n",
    "        inputs = convert_to_tensor(inputs)\n",
    "        input_size = inputs.get_shape().as_list()[1]\n",
    "        dtype = inputs.dtype\n",
    "\n",
    "        with vs.variable_scope(scope or type(self).__name__, reuse = F):  # \"ESNCell\"\n",
    "            \n",
    "            win = vs.get_variable(\"InputMatrix\", [input_size, self._num_units], dtype=dtype,\n",
    "                            trainable=False, initializer=self._win_initializer)\n",
    "            wr = vs.get_variable(\"ReservoirMatrix\", [self._num_units, self._num_units], dtype=dtype,\n",
    "                           trainable=False, initializer=self._wr_initializer)\n",
    "            b = vs.get_variable(\"Bias\", [self._num_units], dtype=dtype, trainable=False, initializer=self._bias_initializer)\n",
    "\n",
    "            in_mat = array_ops.concat([inputs, state], axis=1)\n",
    "            weights_mat = array_ops.concat([win, wr], axis=0)\n",
    "\n",
    "            output = (1 - self._leaky) * state + self._leaky * self._activation(math_ops.matmul(in_mat, weights_mat) + b)\n",
    "\n",
    "        return output, output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MackeyGlass(tr_size=500, washout_size=50, units=30, connectivity=0.2, scale=0.7, elements=2000):\n",
    "    print(\"Fetching data...\")\n",
    "    data_str = requests.get('https://raw.githubusercontent.com/RomainPastureau/Reservoir-Jupyter/master/MackeyGlass_t17.txt').content\n",
    "    \n",
    "    #data = map(float, data_str.splitlines()[:elements])\n",
    "    data = [float(s) for s in data_str.splitlines()[:elements]]\n",
    "    data_t = tf.reshape(tf.constant(data), [1, elements, 1])\n",
    "    esn = ESNCell(units, connectivity, scale)\n",
    "\n",
    "    print(\"Building graph...\")\n",
    "    outputs, final_state = tf.nn.dynamic_rnn(esn, data_t, dtype=tf.float32)\n",
    "    washed = tf.squeeze(tf.slice(outputs, [0, washout_size, 0], [-1, -1, -1]))\n",
    "\n",
    "    with tf.Session() as S:\n",
    "        S.run(tf.global_variables_initializer())\n",
    "\n",
    "        print(\"Computing embeddings...\")\n",
    "        res = S.run(washed)\n",
    "\n",
    "        print(\"Computing direct solution...\")\n",
    "        state = np.array(res)\n",
    "        tr_state = np.mat(state[:tr_size])\n",
    "        ts_state = np.mat(state[tr_size:])\n",
    "        wout = np.transpose(np.mat(data[washout_size+1:tr_size+washout_size+1]) * np.transpose(np.linalg.pinv(tr_state)))\n",
    "\n",
    "        print(\"Testing performance...\")\n",
    "        ts_out = np.mat((np.transpose(ts_state * wout).tolist())[0][:-1])\n",
    "        ts_y = np.mat(data[washout_size+tr_size+1:])\n",
    "\n",
    "        ts_mse = np.mean(np.square(ts_y - ts_out))\n",
    "\n",
    "    print(\"Test MSE: \" + str(ts_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_data(filename,preproc = False):\n",
    "    #get the data\n",
    "    with open (filename) as f:\n",
    "        txt_data = [x.split(';') for x in f.readlines()]\n",
    "        tt = [x[3].strip() for x in txt_data[1:]]\n",
    "        rf = [x[4].strip() for x in txt_data[1:]]\n",
    "        data = np.array((tt,rf),dtype=float)\n",
    "        if preproc:\n",
    "            #scale the data to 0:1\n",
    "            data[0,:] /= np.max(data[0,:])\n",
    "            data[1,:] /= np.max(data[1,:])\n",
    "            #whiten the data\n",
    "            data[0,:] = (data[0,:] - np.mean(data[0,:]))/np.std(data[0,:])\n",
    "            data[1,:] = (data[1,:] - np.mean(data[1,:]))/np.std(data[1,:])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def break_sequence(data,lookback):\n",
    "    #data assumed to be shape (variables,timesteps)\n",
    "    n = data.shape[1]\n",
    "    windows = [data[:,i - lookback : i] for i in np.arange(lookback,n)]\n",
    "    sequence = np.stack(windows,axis = 1)\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weather_esn():\n",
    "    #get the (pre-processed) data\n",
    "    filename = 'temperature_toy.txt'\n",
    "    preproc = True\n",
    "    #get the data\n",
    "    with open (filename) as f:\n",
    "        txt_data = [x.split(';') for x in f.readlines()]\n",
    "        tt = [x[3].strip() for x in txt_data[1:]]\n",
    "        rf = [x[4].strip() for x in txt_data[1:]]\n",
    "        data = np.array((tt,rf),dtype=float)\n",
    "        if preproc:\n",
    "            #scale the data to 0:1\n",
    "            data[0,:] /= np.max(data[0,:])\n",
    "            data[1,:] /= np.max(data[1,:])\n",
    "            #whiten the data\n",
    "            data[0,:] = (data[0,:] - np.mean(data[0,:]))/np.std(data[0,:])\n",
    "            data[1,:] = (data[1,:] - np.mean(data[1,:]))/np.std(data[1,:])\n",
    "    #given the data, break it up into smaller sequences\n",
    "    seq = break_sequence(data,25)\n",
    "    #make a train and a test set\n",
    "    train = seq[:,:100,:]\n",
    "    test = seq[:,100:,:]\n",
    "    #take the first elements of the sequence to predict the last\n",
    "    x_train = train[:,:,:24]\n",
    "    t_train = train[:,:,24]\n",
    "    x_test = test[:,:,:24]\n",
    "    t_test = test[:,:,24]\n",
    "    #create the esn cell\n",
    "    esn = ESNCell(50,0.2,0.7)\n",
    "    #run\n",
    "    with tf.Session() as S:\n",
    "        S.run(tf.global_variables_initializer())\n",
    "        #for each timestep\n",
    "        state = tf.constant(0, shape = [100,50],dtype = tf.float64)\n",
    "        for t in range(24):\n",
    "            y, state = esn(x_train[:,:,t].T,state)\n",
    "            variable.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"ESNCell_24/add_1:0\", shape=(100, 50), dtype=float64)\n",
      "Tensor(\"ESNCell_25/add_1:0\", shape=(100, 50), dtype=float64)\n",
      "Tensor(\"ESNCell_26/add_1:0\", shape=(100, 50), dtype=float64)\n",
      "Tensor(\"ESNCell_27/add_1:0\", shape=(100, 50), dtype=float64)\n",
      "Tensor(\"ESNCell_28/add_1:0\", shape=(100, 50), dtype=float64)\n",
      "Tensor(\"ESNCell_29/add_1:0\", shape=(100, 50), dtype=float64)\n",
      "Tensor(\"ESNCell_30/add_1:0\", shape=(100, 50), dtype=float64)\n",
      "Tensor(\"ESNCell_31/add_1:0\", shape=(100, 50), dtype=float64)\n",
      "Tensor(\"ESNCell_32/add_1:0\", shape=(100, 50), dtype=float64)\n",
      "Tensor(\"ESNCell_33/add_1:0\", shape=(100, 50), dtype=float64)\n",
      "Tensor(\"ESNCell_34/add_1:0\", shape=(100, 50), dtype=float64)\n",
      "Tensor(\"ESNCell_35/add_1:0\", shape=(100, 50), dtype=float64)\n",
      "Tensor(\"ESNCell_36/add_1:0\", shape=(100, 50), dtype=float64)\n",
      "Tensor(\"ESNCell_37/add_1:0\", shape=(100, 50), dtype=float64)\n",
      "Tensor(\"ESNCell_38/add_1:0\", shape=(100, 50), dtype=float64)\n",
      "Tensor(\"ESNCell_39/add_1:0\", shape=(100, 50), dtype=float64)\n",
      "Tensor(\"ESNCell_40/add_1:0\", shape=(100, 50), dtype=float64)\n",
      "Tensor(\"ESNCell_41/add_1:0\", shape=(100, 50), dtype=float64)\n",
      "Tensor(\"ESNCell_42/add_1:0\", shape=(100, 50), dtype=float64)\n",
      "Tensor(\"ESNCell_43/add_1:0\", shape=(100, 50), dtype=float64)\n",
      "Tensor(\"ESNCell_44/add_1:0\", shape=(100, 50), dtype=float64)\n",
      "Tensor(\"ESNCell_45/add_1:0\", shape=(100, 50), dtype=float64)\n",
      "Tensor(\"ESNCell_46/add_1:0\", shape=(100, 50), dtype=float64)\n",
      "Tensor(\"ESNCell_47/add_1:0\", shape=(100, 50), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "variable = []\n",
    "weather_esn()\n",
    "for y in variable:\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data('temperature_toy.txt',True)\n",
    "seq = break_sequence(data,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
